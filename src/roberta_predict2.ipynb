{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce C N E scores using RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fairseq.data.data_utils import collate_tokens\n",
    "import pandas as pd\n",
    "\n",
    "# load roberta model.\n",
    "torch.hub.set_dir('../../roberta/hub')\n",
    "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')  # loading this way works.\n",
    "roberta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_map = {\n",
    "    0: 'contradiction',\n",
    "    1: 'neutral',\n",
    "    2: 'entailment'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter path to csv/tsv file:\n",
      " ../data/Astro1_decomposed_clean_pairs.csv\n",
      "enter delimiter\n",
      " ,\n",
      "enter save path\n",
      "\n",
      " ../data/roberta/Astro1_decomposed_clean_pairs_classes.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0               first  \\\n",
      "0           0  You never give up.   \n",
      "1           1  You never give up.   \n",
      "2           2  You never give up.   \n",
      "3           3  You never give up.   \n",
      "4           4  You never give up.   \n",
      "\n",
      "                                              second  \n",
      "0  You never find it difficult to change your min...  \n",
      "1  Whatever you have set your sights on, you refu...  \n",
      "2  You are patient unless someone takes you too far.  \n",
      "3  You are usually slow to anger unless someone t...  \n",
      "4                                  You are reliable.  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter batch size (integer):\n",
      " 5\n"
     ]
    }
   ],
   "source": [
    "# set paths and parameters.\n",
    "data_dir = input(\"enter path to csv/tsv file:\\n\")\n",
    "delim = input(\"enter delimiter\\n\")\n",
    "\n",
    "with open(data_dir) as f:\n",
    "    data_df = pd.read_csv(f, delimiter=delim)\n",
    "\n",
    "print(data_df.head())\n",
    "\n",
    "batch_size = int(input(\"enter batch size (integer):\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 1 predictions to ../data/Astro1_decomposed_clean_pairs_roberta.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>C</th>\n",
       "      <th>N</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>0.880442</td>\n",
       "      <td>0.096760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entailment</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.039801</td>\n",
       "      <td>0.958454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>0.990273</td>\n",
       "      <td>0.004845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.052050</td>\n",
       "      <td>0.944104</td>\n",
       "      <td>0.003846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entailment</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.161846</td>\n",
       "      <td>0.836661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predicted_class         C         N         E\n",
       "0         neutral  0.022798  0.880442  0.096760\n",
       "1      entailment  0.001746  0.039801  0.958454\n",
       "2         neutral  0.004882  0.990273  0.004845\n",
       "3         neutral  0.052050  0.944104  0.003846\n",
       "4      entailment  0.001493  0.161846  0.836661"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>C</th>\n",
       "      <th>N</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>entailment</td>\n",
       "      <td>0.042239</td>\n",
       "      <td>0.253214</td>\n",
       "      <td>0.704547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.655430</td>\n",
       "      <td>0.302836</td>\n",
       "      <td>0.041734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.102161</td>\n",
       "      <td>0.781847</td>\n",
       "      <td>0.115993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>entailment</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.081088</td>\n",
       "      <td>0.918138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>0.599679</td>\n",
       "      <td>0.196910</td>\n",
       "      <td>0.203411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted_class         C         N         E\n",
       "1076      entailment  0.042239  0.253214  0.704547\n",
       "1077   contradiction  0.655430  0.302836  0.041734\n",
       "1078         neutral  0.102161  0.781847  0.115993\n",
       "1079      entailment  0.000774  0.081088  0.918138\n",
       "1080   contradiction  0.599679  0.196910  0.203411"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import exp\n",
    "\n",
    "results = list()\n",
    "\n",
    "for j in range(1, int(len(data_df)/batch_size + 1)):\n",
    "    batch_of_pairs = []\n",
    "    for i in range(j*batch_size-batch_size, j*batch_size):\n",
    "        batch_of_pairs.append([data_df.iloc[i]['first'], data_df.iloc[i]['second']])\n",
    "\n",
    "    batch = collate_tokens(\n",
    "        [roberta.encode(pair[0], pair[1]) for pair in batch_of_pairs], pad_idx=1\n",
    "    )\n",
    "    logprobs0 = roberta.predict('mnli', batch)\n",
    "    classes_tsr0 = logprobs0.argmax(dim=1)\n",
    "    classes_arr0 = classes_tsr0.numpy()\n",
    "    \n",
    "    # other direction.\n",
    "    batch = collate_tokens(\n",
    "        [roberta.encode(pair[1], pair[0]) for pair in batch_of_pairs], pad_idx=1\n",
    "    )\n",
    "    logprobs1 = roberta.predict('mnli', batch)\n",
    "    classes_tsr1 = logprobs1.argmax(dim=1)\n",
    "    classes_arr1 = classes_tsr1.numpy()\n",
    "    \n",
    "    for k in range(len(classes_arr0)):\n",
    "        max0 = logprobs0[k][classes_arr0[k]].item()\n",
    "        max1 = logprobs1[k][classes_arr1[k]].item()\n",
    "        max_dir = np.argmax([max0, max1])\n",
    "        #print(f\"max_dir: {max_dir}\")\n",
    "        if max_dir == 0:\n",
    "            final_logprobs = logprobs0[k][0], logprobs0[k][1], logprobs0[k][2]\n",
    "        else:\n",
    "            final_logprobs = logprobs1[k][0], logprobs1[k][1], logprobs1[k][2]\n",
    "\n",
    "        final_logprobs_list = [logprob.item() for logprob in final_logprobs]\n",
    "        prob_list =  [pow(exp(1), logprob) for logprob in final_logprobs_list]\n",
    "        #print(prob_list)\n",
    "        predicted_classnum = np.argmax(prob_list)\n",
    "        #print(predicted_classnum)\n",
    "        row = [output_map[predicted_classnum], prob_list[0], prob_list[1], prob_list[2]]\n",
    "        results.append(row)\n",
    "\n",
    "remainder = len(data_df) % batch_size\n",
    "\n",
    "if remainder > 0:\n",
    "    batch_of_pairs = []\n",
    "    for i in range(len(data_df) - remainder, len(data_df)):\n",
    "        batch_of_pairs.append([data_df.iloc[i]['first'], data_df.iloc[i]['second']])\n",
    "        \n",
    "    batch = collate_tokens(\n",
    "        [roberta.encode(pair[0], pair[1]) for pair in batch_of_pairs], pad_idx=1\n",
    "    )\n",
    "    logprobs0 = roberta.predict('mnli', batch)\n",
    "    classes_tsr0 = logprobs0.argmax(dim=1)\n",
    "    classes_arr0 = classes_tsr0.numpy()\n",
    "    \n",
    "    # other direction.\n",
    "    batch = collate_tokens(\n",
    "        [roberta.encode(pair[1], pair[0]) for pair in batch_of_pairs], pad_idx=1\n",
    "    )\n",
    "    logprobs1 = roberta.predict('mnli', batch)\n",
    "    classes_tsr1 = logprobs1.argmax(dim=1)\n",
    "    classes_arr1 = classes_tsr1.numpy()\n",
    "    \n",
    "    for k in range(len(classes_arr0)):\n",
    "        max0 = logprobs0[k][classes_arr0[k]].item()\n",
    "        max1 = logprobs1[k][classes_arr1[k]].item()\n",
    "        max_dir = np.argmax([max0, max1])\n",
    "        #print(f\"max_dir: {max_dir}\")\n",
    "        if max_dir == 0:\n",
    "            final_logprobs = logprobs0[k][0], logprobs0[k][1], logprobs0[k][2]\n",
    "        else:\n",
    "            final_logprobs = logprobs1[k][0], logprobs1[k][1], logprobs1[k][2]\n",
    "\n",
    "        final_logprobs_list = [logprob.item() for logprob in final_logprobs]\n",
    "        prob_list =  [pow(exp(1), logprob) for logprob in final_logprobs_list]\n",
    "        #print(prob_list)\n",
    "        predicted_classnum = np.argmax(prob_list)\n",
    "        #print(predicted_classnum)\n",
    "        row = [output_map[predicted_classnum], prob_list[0], prob_list[1], prob_list[2]]\n",
    "        results.append(row)\n",
    "            \n",
    "    print(f'saved {remainder} predictions to {save_path}')\n",
    "\n",
    "results_df = pd.DataFrame(data=results, columns=[\"predicted_class\", \"C\", \"N\", \"E\"])\n",
    "display(results_df.head(), results_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter save path for csv file:\n",
      " ../data/roberta/Astro1_decomposed_clean_pairs_roberta.csv\n"
     ]
    }
   ],
   "source": [
    "save_path = input(\"enter save path for csv file:\\n\")\n",
    "results_df.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
